
# fo.ai â€“ Cloud Cost Intelligence

**Version:** `v0.1.3`  
**Tagline:** Your smart assistant for optimizing cloud costs, starting with AWS EC2.

---

## ðŸ§­ Overview

`fo.ai` is a lightweight, intelligent tool for identifying cost-saving opportunities in your AWS environment. Backed by LLMs, rule engines, Redis memory, and a clean UI, it supports both one-shot queries and streaming AI responses.

---

## ðŸš€ Features

- âœ… EC2 instance cost analysis using CloudWatch metrics
- âœ… Static rules engine with customizable logic
- âœ… Redis-backed memory (for future personalization)
- âœ… LLM-powered summaries (streamed or static)
- âœ… FastAPI backend for APIs
- âœ… Streamlit web UI with toggle modes
- âœ… CLI tool for local interaction
- âœ… Logging, live tailing, and process control

---

## ðŸ› ï¸ Setup Instructions

### 1. Clone the repo and install requirements

```bash
git clone https://github.com/your-org/fo.ai.git
cd fo.ai
conda activate foai-env  # or your preferred virtualenv
pip install -r requirements.txt
```

### 2. Setup `.env`

```env
FOAI_API_URL=http://localhost:8000
USE_MOCK_DATA=true
```

---

## ðŸ§ª Running Locally

### Option 1: Full app (API + UI)

```bash
python foai_cli.py server start all
```

Then open: [http://localhost:8501](http://localhost:8501)

---

## ðŸ§° CLI Usage

```bash
python foai_cli.py --help
```

### ðŸ§  Ask a cost question

```bash
python foai_cli.py ask "How can I optimize EC2 usage in us-west-1?"
```

### ðŸ”„ Stream LLM output

```bash
python foai_cli.py ask "Are there underutilized EC2s?" --stream
```

### ðŸ“¡ Check API status

```bash
python foai_cli.py status
```

### â˜ï¸ Manage Servers

```bash
python foai_cli.py server start all
python foai_cli.py server stop all
python foai_cli.py server forcekill all
```

### ðŸ“œ View Logs

```bash
python foai_cli.py logs api
python foai_cli.py logs ui
```

---

## âš¡ Setup CLI Alias (Optional)

To use `foai` as a global command:

```bash
echo 'alias foai="python /full/path/to/foai_cli.py"' >> ~/.zshrc  # or ~/.bashrc
source ~/.zshrc  # or source ~/.bashrc
```

Then use like:

```bash
foai ask "How do I save on EC2?"
foai server start all
```

---

## ðŸ§ª Development Workflow

- Main API: [`api.py`](./api.py)
- CLI Tool: [`foai_cli.py`](./foai_cli.py)
- Web UI: [`foai_ui.py`](./foai_ui.py)
- Rule Engine: [`rules/aws/ec2_rules.py`](./rules/aws/ec2_rules.py)
- Redis Memory: [`memory/`](./memory/)
- Logs: `logs/api.log`, `logs/ui.log`

---

## ðŸ§­ Roadmap

- [x] EC2 Analyzer (mock + live)
- [x] Streaming LLM responses
- [x] CLI support + logging
- [ ] Personalized rules via Redis (Spike 1.2)
- [ ] LangGraph memory node (Spike 3)
- [ ] S3 and other service optimizations
- [ ] Slack/Teams integrations

---

## ðŸ§  Powered By

- [LangChain](https://github.com/langchain-ai/langchain)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://streamlit.io/)
- [Redis](https://redis.io/)
- [Open Source LLMs via Ollama](https://ollama.com/)

---

## ðŸ‘¥ License & Credits

MIT License â€“ Built with â™¥ by cloud cost nerds.
